{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJMDUdcnRHz0UCeawDSTuZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safdarjung/saf/blob/main/Pytorch_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6t1SMETAyg5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "N-RxRPsRBEqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = make_classification(n_samples=1000,n_features=20,n_informative=10,n_redundant=7,n_classes=2,random_state=42)"
      ],
      "metadata": {
        "id": "fLx1LAUhBt0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-BbfZsMD59F",
        "outputId": "a67f1f71-0ca3-4994-c3bd-1fc011b687d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, n_features = x.shape"
      ],
      "metadata": {
        "id": "AQ8Y2S5CD8aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test, y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "dHrk2yhzEAXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "dLLUaADmEGyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.from_numpy(x_train).type(torch.float32).to(device)\n",
        "x_test = torch.from_numpy(x_test).type(torch.float32).to(device)\n",
        "y_train = torch.from_numpy(y_train).type(torch.float32).view(-1,1).to(device)\n",
        "y_test = torch.from_numpy(y_test).type(torch.float32).view(-1,1).to(device)"
      ],
      "metadata": {
        "id": "w9CyYf4pEIIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self,n_input_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "\n",
        "    self.linear1 = nn.Linear(n_input_features,20)\n",
        "    self.linear2 = nn.Linear(20,1)\n",
        "    self.elu = nn.ELU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.elu(x)\n",
        "    x = self.linear2(x)\n",
        "    pred = torch.sigmoid(x)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "XLi4ZO-ZEktm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(n_features).to(device)"
      ],
      "metadata": {
        "id": "B-ORik70GE5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()       # binary crossEntropy\n",
        "optimizer = optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "5gAVZys5GIG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train\n",
        "  y_pred = model(x_train)\n",
        "  loss = criterion(y_pred,y_train)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbBDz1Y7GUzn",
        "outputId": "b3a1752c-9131-4c4d-ae29-6b30ae39d1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.3590\n",
            "epoch: 20, loss = 0.3581\n",
            "epoch: 30, loss = 0.3573\n",
            "epoch: 40, loss = 0.3566\n",
            "epoch: 50, loss = 0.3558\n",
            "epoch: 60, loss = 0.3551\n",
            "epoch: 70, loss = 0.3543\n",
            "epoch: 80, loss = 0.3536\n",
            "epoch: 90, loss = 0.3529\n",
            "epoch: 100, loss = 0.3522\n",
            "epoch: 110, loss = 0.3515\n",
            "epoch: 120, loss = 0.3509\n",
            "epoch: 130, loss = 0.3502\n",
            "epoch: 140, loss = 0.3496\n",
            "epoch: 150, loss = 0.3490\n",
            "epoch: 160, loss = 0.3483\n",
            "epoch: 170, loss = 0.3477\n",
            "epoch: 180, loss = 0.3471\n",
            "epoch: 190, loss = 0.3466\n",
            "epoch: 200, loss = 0.3460\n",
            "epoch: 210, loss = 0.3454\n",
            "epoch: 220, loss = 0.3449\n",
            "epoch: 230, loss = 0.3443\n",
            "epoch: 240, loss = 0.3438\n",
            "epoch: 250, loss = 0.3432\n",
            "epoch: 260, loss = 0.3427\n",
            "epoch: 270, loss = 0.3422\n",
            "epoch: 280, loss = 0.3417\n",
            "epoch: 290, loss = 0.3412\n",
            "epoch: 300, loss = 0.3407\n",
            "epoch: 310, loss = 0.3402\n",
            "epoch: 320, loss = 0.3397\n",
            "epoch: 330, loss = 0.3393\n",
            "epoch: 340, loss = 0.3388\n",
            "epoch: 350, loss = 0.3383\n",
            "epoch: 360, loss = 0.3379\n",
            "epoch: 370, loss = 0.3374\n",
            "epoch: 380, loss = 0.3370\n",
            "epoch: 390, loss = 0.3365\n",
            "epoch: 400, loss = 0.3361\n",
            "epoch: 410, loss = 0.3356\n",
            "epoch: 420, loss = 0.3352\n",
            "epoch: 430, loss = 0.3348\n",
            "epoch: 440, loss = 0.3344\n",
            "epoch: 450, loss = 0.3339\n",
            "epoch: 460, loss = 0.3335\n",
            "epoch: 470, loss = 0.3331\n",
            "epoch: 480, loss = 0.3327\n",
            "epoch: 490, loss = 0.3323\n",
            "epoch: 500, loss = 0.3319\n",
            "epoch: 510, loss = 0.3315\n",
            "epoch: 520, loss = 0.3311\n",
            "epoch: 530, loss = 0.3307\n",
            "epoch: 540, loss = 0.3303\n",
            "epoch: 550, loss = 0.3299\n",
            "epoch: 560, loss = 0.3296\n",
            "epoch: 570, loss = 0.3292\n",
            "epoch: 580, loss = 0.3288\n",
            "epoch: 590, loss = 0.3284\n",
            "epoch: 600, loss = 0.3280\n",
            "epoch: 610, loss = 0.3277\n",
            "epoch: 620, loss = 0.3273\n",
            "epoch: 630, loss = 0.3269\n",
            "epoch: 640, loss = 0.3265\n",
            "epoch: 650, loss = 0.3262\n",
            "epoch: 660, loss = 0.3258\n",
            "epoch: 670, loss = 0.3255\n",
            "epoch: 680, loss = 0.3251\n",
            "epoch: 690, loss = 0.3247\n",
            "epoch: 700, loss = 0.3244\n",
            "epoch: 710, loss = 0.3240\n",
            "epoch: 720, loss = 0.3237\n",
            "epoch: 730, loss = 0.3233\n",
            "epoch: 740, loss = 0.3229\n",
            "epoch: 750, loss = 0.3226\n",
            "epoch: 760, loss = 0.3222\n",
            "epoch: 770, loss = 0.3219\n",
            "epoch: 780, loss = 0.3215\n",
            "epoch: 790, loss = 0.3212\n",
            "epoch: 800, loss = 0.3208\n",
            "epoch: 810, loss = 0.3205\n",
            "epoch: 820, loss = 0.3201\n",
            "epoch: 830, loss = 0.3198\n",
            "epoch: 840, loss = 0.3195\n",
            "epoch: 850, loss = 0.3191\n",
            "epoch: 860, loss = 0.3188\n",
            "epoch: 870, loss = 0.3184\n",
            "epoch: 880, loss = 0.3181\n",
            "epoch: 890, loss = 0.3177\n",
            "epoch: 900, loss = 0.3174\n",
            "epoch: 910, loss = 0.3170\n",
            "epoch: 920, loss = 0.3167\n",
            "epoch: 930, loss = 0.3164\n",
            "epoch: 940, loss = 0.3160\n",
            "epoch: 950, loss = 0.3157\n",
            "epoch: 960, loss = 0.3153\n",
            "epoch: 970, loss = 0.3150\n",
            "epoch: 980, loss = 0.3146\n",
            "epoch: 990, loss = 0.3143\n",
            "epoch: 1000, loss = 0.3140\n",
            "epoch: 1010, loss = 0.3136\n",
            "epoch: 1020, loss = 0.3133\n",
            "epoch: 1030, loss = 0.3129\n",
            "epoch: 1040, loss = 0.3126\n",
            "epoch: 1050, loss = 0.3122\n",
            "epoch: 1060, loss = 0.3119\n",
            "epoch: 1070, loss = 0.3116\n",
            "epoch: 1080, loss = 0.3112\n",
            "epoch: 1090, loss = 0.3109\n",
            "epoch: 1100, loss = 0.3105\n",
            "epoch: 1110, loss = 0.3102\n",
            "epoch: 1120, loss = 0.3099\n",
            "epoch: 1130, loss = 0.3095\n",
            "epoch: 1140, loss = 0.3092\n",
            "epoch: 1150, loss = 0.3088\n",
            "epoch: 1160, loss = 0.3085\n",
            "epoch: 1170, loss = 0.3081\n",
            "epoch: 1180, loss = 0.3078\n",
            "epoch: 1190, loss = 0.3075\n",
            "epoch: 1200, loss = 0.3071\n",
            "epoch: 1210, loss = 0.3068\n",
            "epoch: 1220, loss = 0.3064\n",
            "epoch: 1230, loss = 0.3061\n",
            "epoch: 1240, loss = 0.3057\n",
            "epoch: 1250, loss = 0.3054\n",
            "epoch: 1260, loss = 0.3050\n",
            "epoch: 1270, loss = 0.3047\n",
            "epoch: 1280, loss = 0.3044\n",
            "epoch: 1290, loss = 0.3040\n",
            "epoch: 1300, loss = 0.3037\n",
            "epoch: 1310, loss = 0.3033\n",
            "epoch: 1320, loss = 0.3030\n",
            "epoch: 1330, loss = 0.3026\n",
            "epoch: 1340, loss = 0.3023\n",
            "epoch: 1350, loss = 0.3019\n",
            "epoch: 1360, loss = 0.3016\n",
            "epoch: 1370, loss = 0.3012\n",
            "epoch: 1380, loss = 0.3009\n",
            "epoch: 1390, loss = 0.3005\n",
            "epoch: 1400, loss = 0.3002\n",
            "epoch: 1410, loss = 0.2998\n",
            "epoch: 1420, loss = 0.2995\n",
            "epoch: 1430, loss = 0.2991\n",
            "epoch: 1440, loss = 0.2988\n",
            "epoch: 1450, loss = 0.2984\n",
            "epoch: 1460, loss = 0.2981\n",
            "epoch: 1470, loss = 0.2978\n",
            "epoch: 1480, loss = 0.2974\n",
            "epoch: 1490, loss = 0.2971\n",
            "epoch: 1500, loss = 0.2967\n",
            "epoch: 1510, loss = 0.2964\n",
            "epoch: 1520, loss = 0.2960\n",
            "epoch: 1530, loss = 0.2956\n",
            "epoch: 1540, loss = 0.2953\n",
            "epoch: 1550, loss = 0.2949\n",
            "epoch: 1560, loss = 0.2946\n",
            "epoch: 1570, loss = 0.2942\n",
            "epoch: 1580, loss = 0.2939\n",
            "epoch: 1590, loss = 0.2935\n",
            "epoch: 1600, loss = 0.2932\n",
            "epoch: 1610, loss = 0.2928\n",
            "epoch: 1620, loss = 0.2925\n",
            "epoch: 1630, loss = 0.2921\n",
            "epoch: 1640, loss = 0.2918\n",
            "epoch: 1650, loss = 0.2914\n",
            "epoch: 1660, loss = 0.2911\n",
            "epoch: 1670, loss = 0.2907\n",
            "epoch: 1680, loss = 0.2904\n",
            "epoch: 1690, loss = 0.2900\n",
            "epoch: 1700, loss = 0.2897\n",
            "epoch: 1710, loss = 0.2893\n",
            "epoch: 1720, loss = 0.2890\n",
            "epoch: 1730, loss = 0.2886\n",
            "epoch: 1740, loss = 0.2882\n",
            "epoch: 1750, loss = 0.2879\n",
            "epoch: 1760, loss = 0.2875\n",
            "epoch: 1770, loss = 0.2872\n",
            "epoch: 1780, loss = 0.2868\n",
            "epoch: 1790, loss = 0.2865\n",
            "epoch: 1800, loss = 0.2861\n",
            "epoch: 1810, loss = 0.2858\n",
            "epoch: 1820, loss = 0.2854\n",
            "epoch: 1830, loss = 0.2851\n",
            "epoch: 1840, loss = 0.2847\n",
            "epoch: 1850, loss = 0.2843\n",
            "epoch: 1860, loss = 0.2840\n",
            "epoch: 1870, loss = 0.2836\n",
            "epoch: 1880, loss = 0.2833\n",
            "epoch: 1890, loss = 0.2829\n",
            "epoch: 1900, loss = 0.2826\n",
            "epoch: 1910, loss = 0.2822\n",
            "epoch: 1920, loss = 0.2819\n",
            "epoch: 1930, loss = 0.2815\n",
            "epoch: 1940, loss = 0.2812\n",
            "epoch: 1950, loss = 0.2808\n",
            "epoch: 1960, loss = 0.2805\n",
            "epoch: 1970, loss = 0.2801\n",
            "epoch: 1980, loss = 0.2797\n",
            "epoch: 1990, loss = 0.2794\n",
            "epoch: 2000, loss = 0.2790\n",
            "epoch: 2010, loss = 0.2787\n",
            "epoch: 2020, loss = 0.2783\n",
            "epoch: 2030, loss = 0.2780\n",
            "epoch: 2040, loss = 0.2776\n",
            "epoch: 2050, loss = 0.2773\n",
            "epoch: 2060, loss = 0.2769\n",
            "epoch: 2070, loss = 0.2766\n",
            "epoch: 2080, loss = 0.2762\n",
            "epoch: 2090, loss = 0.2759\n",
            "epoch: 2100, loss = 0.2755\n",
            "epoch: 2110, loss = 0.2752\n",
            "epoch: 2120, loss = 0.2748\n",
            "epoch: 2130, loss = 0.2745\n",
            "epoch: 2140, loss = 0.2741\n",
            "epoch: 2150, loss = 0.2738\n",
            "epoch: 2160, loss = 0.2734\n",
            "epoch: 2170, loss = 0.2731\n",
            "epoch: 2180, loss = 0.2727\n",
            "epoch: 2190, loss = 0.2724\n",
            "epoch: 2200, loss = 0.2720\n",
            "epoch: 2210, loss = 0.2717\n",
            "epoch: 2220, loss = 0.2713\n",
            "epoch: 2230, loss = 0.2710\n",
            "epoch: 2240, loss = 0.2706\n",
            "epoch: 2250, loss = 0.2703\n",
            "epoch: 2260, loss = 0.2699\n",
            "epoch: 2270, loss = 0.2696\n",
            "epoch: 2280, loss = 0.2693\n",
            "epoch: 2290, loss = 0.2689\n",
            "epoch: 2300, loss = 0.2686\n",
            "epoch: 2310, loss = 0.2682\n",
            "epoch: 2320, loss = 0.2679\n",
            "epoch: 2330, loss = 0.2675\n",
            "epoch: 2340, loss = 0.2672\n",
            "epoch: 2350, loss = 0.2669\n",
            "epoch: 2360, loss = 0.2665\n",
            "epoch: 2370, loss = 0.2662\n",
            "epoch: 2380, loss = 0.2658\n",
            "epoch: 2390, loss = 0.2655\n",
            "epoch: 2400, loss = 0.2652\n",
            "epoch: 2410, loss = 0.2648\n",
            "epoch: 2420, loss = 0.2645\n",
            "epoch: 2430, loss = 0.2642\n",
            "epoch: 2440, loss = 0.2638\n",
            "epoch: 2450, loss = 0.2635\n",
            "epoch: 2460, loss = 0.2632\n",
            "epoch: 2470, loss = 0.2628\n",
            "epoch: 2480, loss = 0.2625\n",
            "epoch: 2490, loss = 0.2622\n",
            "epoch: 2500, loss = 0.2618\n",
            "epoch: 2510, loss = 0.2615\n",
            "epoch: 2520, loss = 0.2612\n",
            "epoch: 2530, loss = 0.2608\n",
            "epoch: 2540, loss = 0.2605\n",
            "epoch: 2550, loss = 0.2602\n",
            "epoch: 2560, loss = 0.2599\n",
            "epoch: 2570, loss = 0.2595\n",
            "epoch: 2580, loss = 0.2592\n",
            "epoch: 2590, loss = 0.2589\n",
            "epoch: 2600, loss = 0.2585\n",
            "epoch: 2610, loss = 0.2582\n",
            "epoch: 2620, loss = 0.2579\n",
            "epoch: 2630, loss = 0.2576\n",
            "epoch: 2640, loss = 0.2573\n",
            "epoch: 2650, loss = 0.2569\n",
            "epoch: 2660, loss = 0.2566\n",
            "epoch: 2670, loss = 0.2563\n",
            "epoch: 2680, loss = 0.2560\n",
            "epoch: 2690, loss = 0.2557\n",
            "epoch: 2700, loss = 0.2553\n",
            "epoch: 2710, loss = 0.2550\n",
            "epoch: 2720, loss = 0.2547\n",
            "epoch: 2730, loss = 0.2544\n",
            "epoch: 2740, loss = 0.2541\n",
            "epoch: 2750, loss = 0.2538\n",
            "epoch: 2760, loss = 0.2534\n",
            "epoch: 2770, loss = 0.2531\n",
            "epoch: 2780, loss = 0.2528\n",
            "epoch: 2790, loss = 0.2525\n",
            "epoch: 2800, loss = 0.2522\n",
            "epoch: 2810, loss = 0.2519\n",
            "epoch: 2820, loss = 0.2516\n",
            "epoch: 2830, loss = 0.2513\n",
            "epoch: 2840, loss = 0.2510\n",
            "epoch: 2850, loss = 0.2507\n",
            "epoch: 2860, loss = 0.2503\n",
            "epoch: 2870, loss = 0.2500\n",
            "epoch: 2880, loss = 0.2497\n",
            "epoch: 2890, loss = 0.2494\n",
            "epoch: 2900, loss = 0.2491\n",
            "epoch: 2910, loss = 0.2488\n",
            "epoch: 2920, loss = 0.2485\n",
            "epoch: 2930, loss = 0.2482\n",
            "epoch: 2940, loss = 0.2479\n",
            "epoch: 2950, loss = 0.2476\n",
            "epoch: 2960, loss = 0.2473\n",
            "epoch: 2970, loss = 0.2470\n",
            "epoch: 2980, loss = 0.2467\n",
            "epoch: 2990, loss = 0.2464\n",
            "epoch: 3000, loss = 0.2461\n",
            "epoch: 3010, loss = 0.2458\n",
            "epoch: 3020, loss = 0.2455\n",
            "epoch: 3030, loss = 0.2452\n",
            "epoch: 3040, loss = 0.2449\n",
            "epoch: 3050, loss = 0.2446\n",
            "epoch: 3060, loss = 0.2443\n",
            "epoch: 3070, loss = 0.2441\n",
            "epoch: 3080, loss = 0.2438\n",
            "epoch: 3090, loss = 0.2435\n",
            "epoch: 3100, loss = 0.2432\n",
            "epoch: 3110, loss = 0.2429\n",
            "epoch: 3120, loss = 0.2426\n",
            "epoch: 3130, loss = 0.2423\n",
            "epoch: 3140, loss = 0.2420\n",
            "epoch: 3150, loss = 0.2417\n",
            "epoch: 3160, loss = 0.2414\n",
            "epoch: 3170, loss = 0.2412\n",
            "epoch: 3180, loss = 0.2409\n",
            "epoch: 3190, loss = 0.2406\n",
            "epoch: 3200, loss = 0.2403\n",
            "epoch: 3210, loss = 0.2400\n",
            "epoch: 3220, loss = 0.2397\n",
            "epoch: 3230, loss = 0.2394\n",
            "epoch: 3240, loss = 0.2392\n",
            "epoch: 3250, loss = 0.2389\n",
            "epoch: 3260, loss = 0.2386\n",
            "epoch: 3270, loss = 0.2383\n",
            "epoch: 3280, loss = 0.2380\n",
            "epoch: 3290, loss = 0.2378\n",
            "epoch: 3300, loss = 0.2375\n",
            "epoch: 3310, loss = 0.2372\n",
            "epoch: 3320, loss = 0.2369\n",
            "epoch: 3330, loss = 0.2367\n",
            "epoch: 3340, loss = 0.2364\n",
            "epoch: 3350, loss = 0.2361\n",
            "epoch: 3360, loss = 0.2358\n",
            "epoch: 3370, loss = 0.2355\n",
            "epoch: 3380, loss = 0.2353\n",
            "epoch: 3390, loss = 0.2350\n",
            "epoch: 3400, loss = 0.2347\n",
            "epoch: 3410, loss = 0.2345\n",
            "epoch: 3420, loss = 0.2342\n",
            "epoch: 3430, loss = 0.2339\n",
            "epoch: 3440, loss = 0.2336\n",
            "epoch: 3450, loss = 0.2334\n",
            "epoch: 3460, loss = 0.2331\n",
            "epoch: 3470, loss = 0.2328\n",
            "epoch: 3480, loss = 0.2326\n",
            "epoch: 3490, loss = 0.2323\n",
            "epoch: 3500, loss = 0.2320\n",
            "epoch: 3510, loss = 0.2318\n",
            "epoch: 3520, loss = 0.2315\n",
            "epoch: 3530, loss = 0.2312\n",
            "epoch: 3540, loss = 0.2310\n",
            "epoch: 3550, loss = 0.2307\n",
            "epoch: 3560, loss = 0.2304\n",
            "epoch: 3570, loss = 0.2302\n",
            "epoch: 3580, loss = 0.2299\n",
            "epoch: 3590, loss = 0.2296\n",
            "epoch: 3600, loss = 0.2294\n",
            "epoch: 3610, loss = 0.2291\n",
            "epoch: 3620, loss = 0.2289\n",
            "epoch: 3630, loss = 0.2286\n",
            "epoch: 3640, loss = 0.2283\n",
            "epoch: 3650, loss = 0.2281\n",
            "epoch: 3660, loss = 0.2278\n",
            "epoch: 3670, loss = 0.2276\n",
            "epoch: 3680, loss = 0.2273\n",
            "epoch: 3690, loss = 0.2270\n",
            "epoch: 3700, loss = 0.2268\n",
            "epoch: 3710, loss = 0.2265\n",
            "epoch: 3720, loss = 0.2263\n",
            "epoch: 3730, loss = 0.2260\n",
            "epoch: 3740, loss = 0.2258\n",
            "epoch: 3750, loss = 0.2255\n",
            "epoch: 3760, loss = 0.2253\n",
            "epoch: 3770, loss = 0.2250\n",
            "epoch: 3780, loss = 0.2248\n",
            "epoch: 3790, loss = 0.2245\n",
            "epoch: 3800, loss = 0.2243\n",
            "epoch: 3810, loss = 0.2240\n",
            "epoch: 3820, loss = 0.2237\n",
            "epoch: 3830, loss = 0.2235\n",
            "epoch: 3840, loss = 0.2232\n",
            "epoch: 3850, loss = 0.2230\n",
            "epoch: 3860, loss = 0.2227\n",
            "epoch: 3870, loss = 0.2225\n",
            "epoch: 3880, loss = 0.2222\n",
            "epoch: 3890, loss = 0.2220\n",
            "epoch: 3900, loss = 0.2218\n",
            "epoch: 3910, loss = 0.2215\n",
            "epoch: 3920, loss = 0.2213\n",
            "epoch: 3930, loss = 0.2210\n",
            "epoch: 3940, loss = 0.2208\n",
            "epoch: 3950, loss = 0.2205\n",
            "epoch: 3960, loss = 0.2203\n",
            "epoch: 3970, loss = 0.2200\n",
            "epoch: 3980, loss = 0.2198\n",
            "epoch: 3990, loss = 0.2195\n",
            "epoch: 4000, loss = 0.2193\n",
            "epoch: 4010, loss = 0.2191\n",
            "epoch: 4020, loss = 0.2188\n",
            "epoch: 4030, loss = 0.2186\n",
            "epoch: 4040, loss = 0.2183\n",
            "epoch: 4050, loss = 0.2181\n",
            "epoch: 4060, loss = 0.2178\n",
            "epoch: 4070, loss = 0.2176\n",
            "epoch: 4080, loss = 0.2174\n",
            "epoch: 4090, loss = 0.2171\n",
            "epoch: 4100, loss = 0.2169\n",
            "epoch: 4110, loss = 0.2166\n",
            "epoch: 4120, loss = 0.2164\n",
            "epoch: 4130, loss = 0.2162\n",
            "epoch: 4140, loss = 0.2159\n",
            "epoch: 4150, loss = 0.2157\n",
            "epoch: 4160, loss = 0.2155\n",
            "epoch: 4170, loss = 0.2152\n",
            "epoch: 4180, loss = 0.2150\n",
            "epoch: 4190, loss = 0.2148\n",
            "epoch: 4200, loss = 0.2145\n",
            "epoch: 4210, loss = 0.2143\n",
            "epoch: 4220, loss = 0.2140\n",
            "epoch: 4230, loss = 0.2138\n",
            "epoch: 4240, loss = 0.2136\n",
            "epoch: 4250, loss = 0.2133\n",
            "epoch: 4260, loss = 0.2131\n",
            "epoch: 4270, loss = 0.2129\n",
            "epoch: 4280, loss = 0.2126\n",
            "epoch: 4290, loss = 0.2124\n",
            "epoch: 4300, loss = 0.2122\n",
            "epoch: 4310, loss = 0.2119\n",
            "epoch: 4320, loss = 0.2117\n",
            "epoch: 4330, loss = 0.2115\n",
            "epoch: 4340, loss = 0.2113\n",
            "epoch: 4350, loss = 0.2110\n",
            "epoch: 4360, loss = 0.2108\n",
            "epoch: 4370, loss = 0.2106\n",
            "epoch: 4380, loss = 0.2103\n",
            "epoch: 4390, loss = 0.2101\n",
            "epoch: 4400, loss = 0.2099\n",
            "epoch: 4410, loss = 0.2096\n",
            "epoch: 4420, loss = 0.2094\n",
            "epoch: 4430, loss = 0.2092\n",
            "epoch: 4440, loss = 0.2090\n",
            "epoch: 4450, loss = 0.2087\n",
            "epoch: 4460, loss = 0.2085\n",
            "epoch: 4470, loss = 0.2083\n",
            "epoch: 4480, loss = 0.2081\n",
            "epoch: 4490, loss = 0.2078\n",
            "epoch: 4500, loss = 0.2076\n",
            "epoch: 4510, loss = 0.2074\n",
            "epoch: 4520, loss = 0.2072\n",
            "epoch: 4530, loss = 0.2069\n",
            "epoch: 4540, loss = 0.2067\n",
            "epoch: 4550, loss = 0.2065\n",
            "epoch: 4560, loss = 0.2063\n",
            "epoch: 4570, loss = 0.2060\n",
            "epoch: 4580, loss = 0.2058\n",
            "epoch: 4590, loss = 0.2056\n",
            "epoch: 4600, loss = 0.2054\n",
            "epoch: 4610, loss = 0.2052\n",
            "epoch: 4620, loss = 0.2049\n",
            "epoch: 4630, loss = 0.2047\n",
            "epoch: 4640, loss = 0.2045\n",
            "epoch: 4650, loss = 0.2043\n",
            "epoch: 4660, loss = 0.2040\n",
            "epoch: 4670, loss = 0.2038\n",
            "epoch: 4680, loss = 0.2036\n",
            "epoch: 4690, loss = 0.2034\n",
            "epoch: 4700, loss = 0.2032\n",
            "epoch: 4710, loss = 0.2030\n",
            "epoch: 4720, loss = 0.2027\n",
            "epoch: 4730, loss = 0.2025\n",
            "epoch: 4740, loss = 0.2023\n",
            "epoch: 4750, loss = 0.2021\n",
            "epoch: 4760, loss = 0.2019\n",
            "epoch: 4770, loss = 0.2017\n",
            "epoch: 4780, loss = 0.2014\n",
            "epoch: 4790, loss = 0.2012\n",
            "epoch: 4800, loss = 0.2010\n",
            "epoch: 4810, loss = 0.2008\n",
            "epoch: 4820, loss = 0.2006\n",
            "epoch: 4830, loss = 0.2004\n",
            "epoch: 4840, loss = 0.2001\n",
            "epoch: 4850, loss = 0.1999\n",
            "epoch: 4860, loss = 0.1997\n",
            "epoch: 4870, loss = 0.1995\n",
            "epoch: 4880, loss = 0.1993\n",
            "epoch: 4890, loss = 0.1991\n",
            "epoch: 4900, loss = 0.1989\n",
            "epoch: 4910, loss = 0.1987\n",
            "epoch: 4920, loss = 0.1984\n",
            "epoch: 4930, loss = 0.1982\n",
            "epoch: 4940, loss = 0.1980\n",
            "epoch: 4950, loss = 0.1978\n",
            "epoch: 4960, loss = 0.1976\n",
            "epoch: 4970, loss = 0.1974\n",
            "epoch: 4980, loss = 0.1972\n",
            "epoch: 4990, loss = 0.1970\n",
            "epoch: 5000, loss = 0.1968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_pred = model(x_test)\n",
        "  y_pred_cls = y_pred.round()\n",
        "  acc = y_pred_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "  print(f'accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRc8vlP-GvX2",
        "outputId": "088a1616-86d4-4345-938c-96cbfad17345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6R0vM-1GHHds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}